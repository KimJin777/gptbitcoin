import os
from dotenv import load_dotenv
load_dotenv()

import requests
import json
from datetime import datetime, timedelta
import time
import pandas as pd

def get_bitcoin_news():
    """
    Google News APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘
    """
    print("=== ë¹„íŠ¸ì½”ì¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ===")
    
    # SerpAPI í‚¤ í™•ì¸
    serp_api_key = os.getenv("SERP_API_KEY")
    if not serp_api_key:
        print("ì˜¤ë¥˜: SERP_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # Google News API ìš”ì²­
        url = "https://serpapi.com/search"
        params = {
            "engine": "google_news",
            "q": "bitcoin cryptocurrency",
            "gl": "kr",  # í•œêµ­
            "hl": "ko",  # í•œêµ­ì–´
            "api_key": serp_api_key,
            "num": 20  # ìµœëŒ€ 20ê°œ ë‰´ìŠ¤
        }
        
        print("Google News API ìš”ì²­ ì¤‘...")
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        # ê²€ìƒ‰ ìƒíƒœ í™•ì¸
        if data.get('search_metadata', {}).get('status') == 'Success':
            news_results = data.get('news_results', [])
            
            if news_results:
                print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(news_results)}ê°œ")
                
                # ë‰´ìŠ¤ ë°ì´í„° ì •ë¦¬
                processed_news = []
                for news in news_results:
                    try:
                        processed_news.append({
                            'title': news.get('title', ''),
                            'link': news.get('link', ''),
                            'snippet': news.get('snippet', ''),
                            'source': news.get('source', ''),
                            'date': news.get('date', ''),
                            'position': news.get('position', 0)
                        })
                    except Exception as e:
                        print(f"ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        continue
                
                return processed_news
            else:
                print("ë‰´ìŠ¤ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
        else:
            print(f"API ìš”ì²­ ì‹¤íŒ¨: {data.get('search_metadata', {}).get('status')}")
            return None
            
    except Exception as e:
        print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def analyze_news_sentiment(news_data):
    """
    ë‰´ìŠ¤ ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
    """
    print("=== ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì¤‘ ===")
    
    if not news_data:
        return None
    
    # ê¸ì •ì /ë¶€ì •ì  í‚¤ì›Œë“œ ì •ì˜
    positive_keywords = [
        'ìƒìŠ¹', 'ê¸‰ë“±', 'ëŒíŒŒ', 'ê°•ì„¸', 'í˜¸ì¬', 'ê¸ì •', 'ë‚™ê´€', 'ì„±ì¥', 'ê¸°ëŒ€',
        'bullish', 'rally', 'surge', 'breakout', 'positive', 'growth', 'optimistic'
    ]
    
    negative_keywords = [
        'í•˜ë½', 'ê¸‰ë½', 'í­ë½', 'ì•½ì„¸', 'ì•…ì¬', 'ë¶€ì •', 'ë¹„ê´€', 'ìœ„í—˜', 'ìš°ë ¤',
        'bearish', 'crash', 'drop', 'decline', 'negative', 'risk', 'concern'
    ]
    
    analyzed_news = []
    
    for news in news_data:
        title = news['title'].lower()
        snippet = news['snippet'].lower()
        full_text = f"{title} {snippet}"
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        positive_count = sum(1 for keyword in positive_keywords if keyword in full_text)
        negative_count = sum(1 for keyword in negative_keywords if keyword in full_text)
        
        # ê°ì • ì ìˆ˜ ê³„ì‚° (-1 ~ 1)
        if positive_count > 0 or negative_count > 0:
            sentiment_score = (positive_count - negative_count) / max(positive_count + negative_count, 1)
        else:
            sentiment_score = 0
        
        # ê°ì • ë¶„ë¥˜
        if sentiment_score > 0.3:
            sentiment = "ê¸ì •"
        elif sentiment_score < -0.3:
            sentiment = "ë¶€ì •"
        else:
            sentiment = "ì¤‘ë¦½"
        
        analyzed_news.append({
            **news,
            'sentiment_score': sentiment_score,
            'sentiment': sentiment,
            'positive_keywords': positive_count,
            'negative_keywords': negative_count
        })
    
    return analyzed_news

def display_news_summary(news_data):
    """
    ë‰´ìŠ¤ ìš”ì•½ í‘œì‹œ
    """
    if not news_data:
        print("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ“° ë¹„íŠ¸ì½”ì¸ ìµœì‹  ë‰´ìŠ¤ í—¤ë“œë¼ì¸")
    print("=" * 80)
    
    # ê°ì •ë³„ í†µê³„
    sentiment_stats = {}
    for news in news_data:
        sentiment = news.get('sentiment', 'ì¤‘ë¦½')
        sentiment_stats[sentiment] = sentiment_stats.get(sentiment, 0) + 1
    
    print(f"\nğŸ“Š ë‰´ìŠ¤ ê°ì • ë¶„ì„ ê²°ê³¼:")
    for sentiment, count in sentiment_stats.items():
        print(f"  {sentiment}: {count}ê°œ")
    
    # ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ
    print(f"\nğŸ“‹ ìƒìœ„ {len(news_data)}ê°œ ë‰´ìŠ¤:")
    for i, news in enumerate(news_data, 1):
        sentiment_emoji = {
            "ê¸ì •": "ğŸŸ¢",
            "ë¶€ì •": "ğŸ”´", 
            "ì¤‘ë¦½": "ğŸŸ¡"
        }.get(news['sentiment'], "âšª")
        
        print(f"\n{i}. {sentiment_emoji} {news['title']}")
        print(f"   ğŸ“° {news['source']} | {news['date']}")
        print(f"   ğŸ“ {news['snippet'][:100]}...")
        print(f"   ğŸ”— {news['link']}")
        print(f"   ğŸ’­ ê°ì •: {news['sentiment']} (ì ìˆ˜: {news['sentiment_score']:.2f})")

def get_market_impact_analysis(news_data):
    """
    ë‰´ìŠ¤ ê¸°ë°˜ ì‹œì¥ ì˜í–¥ ë¶„ì„
    """
    print("\n=== ì‹œì¥ ì˜í–¥ ë¶„ì„ ===")
    
    if not news_data:
        return
    
    # ê°ì • ì ìˆ˜ í‰ê· 
    sentiment_scores = [news['sentiment_score'] for news in news_data]
    avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
    
    # ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ë¹„ìœ¨
    positive_news = [news for news in news_data if news['sentiment'] == 'ê¸ì •']
    negative_news = [news for news in news_data if news['sentiment'] == 'ë¶€ì •']
    neutral_news = [news for news in news_data if news['sentiment'] == 'ì¤‘ë¦½']
    
    total_news = len(news_data)
    positive_ratio = len(positive_news) / total_news * 100
    negative_ratio = len(negative_news) / total_news * 100
    neutral_ratio = len(neutral_news) / total_news * 100
    
    print(f"ğŸ“ˆ ì „ì²´ ë‰´ìŠ¤ ê°ì • ì ìˆ˜: {avg_sentiment:.2f}")
    print(f"ğŸ“Š ë‰´ìŠ¤ ë¶„í¬:")
    print(f"  ğŸŸ¢ ê¸ì •ì  ë‰´ìŠ¤: {len(positive_news)}ê°œ ({positive_ratio:.1f}%)")
    print(f"  ğŸ”´ ë¶€ì •ì  ë‰´ìŠ¤: {len(negative_news)}ê°œ ({negative_ratio:.1f}%)")
    print(f"  ğŸŸ¡ ì¤‘ë¦½ì  ë‰´ìŠ¤: {len(neutral_news)}ê°œ ({neutral_ratio:.1f}%)")
    
    # ì‹œì¥ ì˜í–¥ ì˜ˆì¸¡
    if avg_sentiment > 0.2:
        market_impact = "ğŸŸ¢ ê¸ì •ì  - ìƒìŠ¹ ì••ë ¥ ì˜ˆìƒ"
    elif avg_sentiment < -0.2:
        market_impact = "ğŸ”´ ë¶€ì •ì  - í•˜ë½ ì••ë ¥ ì˜ˆìƒ"
    else:
        market_impact = "ğŸŸ¡ ì¤‘ë¦½ì  - íš¡ë³´ ì˜ˆìƒ"
    
    print(f"\nğŸ¯ ì‹œì¥ ì˜í–¥ ì˜ˆì¸¡: {market_impact}")
    
    # ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
    print(f"\nğŸ” ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„:")
    all_titles = " ".join([news['title'] + " " + news['snippet'] for news in news_data]).lower()
    
    keywords = {
        'ê°€ê²©': all_titles.count('ê°€ê²©') + all_titles.count('price'),
        'ê·œì œ': all_titles.count('ê·œì œ') + all_titles.count('regulation'),
        'ê¸°ê´€': all_titles.count('ê¸°ê´€') + all_titles.count('institution'),
        'ETF': all_titles.count('etf'),
        'ì±„íƒ': all_titles.count('ì±„íƒ') + all_titles.count('adoption'),
        'ê¸°ìˆ ': all_titles.count('ê¸°ìˆ ') + all_titles.count('technology')
    }
    
    for keyword, count in sorted(keywords.items(), key=lambda x: x[1], reverse=True):
        if count > 0:
            print(f"  {keyword}: {count}íšŒ ì–¸ê¸‰")

def main_news_cycle():
    """
    ë©”ì¸ ë‰´ìŠ¤ ë¶„ì„ ì‚¬ì´í´
    """
    print("=" * 80)
    print("ğŸ“° ë¹„íŠ¸ì½”ì¸ ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 80)
    
    try:
        # ë‰´ìŠ¤ ìˆ˜ì§‘
        news_data = get_bitcoin_news()
        
        if news_data:
            # ë‰´ìŠ¤ ê°ì • ë¶„ì„
            analyzed_news = analyze_news_sentiment(news_data)
            
            if analyzed_news:
                # ë‰´ìŠ¤ ìš”ì•½ í‘œì‹œ
                display_news_summary(analyzed_news)
                
                # ì‹œì¥ ì˜í–¥ ë¶„ì„
                get_market_impact_analysis(analyzed_news)
                
                # ë¶„ì„ ê²°ê³¼ ì €ì¥
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"bitcoin_news_analysis_{timestamp}.json"
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump({
                        'analysis_time': datetime.now().isoformat(),
                        'total_news': len(analyzed_news),
                        'news_data': analyzed_news
                    }, f, ensure_ascii=False, indent=2)
                
                print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print("ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤íŒ¨")
        else:
            print("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    import time
    
    print("ğŸš€ ë¹„íŠ¸ì½”ì¸ ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ’¡ .env íŒŒì¼ì— SERP_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    print("ğŸ’¡ ì˜ˆì‹œ: SERP_API_KEY=your_serpapi_key_here")
    print()
    
    while True:
        try:
            # ë©”ì¸ ë‰´ìŠ¤ ë¶„ì„ ì‚¬ì´í´ ì‹¤í–‰
            main_news_cycle()
            
            print("\n" + "=" * 80)
            print("â° 30ë¶„ í›„ ë‹¤ìŒ ë‰´ìŠ¤ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            print("=" * 80 + "\n")
            time.sleep(60 * 30)  # 30ë¶„ ëŒ€ê¸°
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ğŸ”„ 5ë¶„ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            time.sleep(60 * 5)
